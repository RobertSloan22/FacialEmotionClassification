
<!doctype html>
<html lang="en" data-bs-theme="auto">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="TensorFlow.js Facial Emotion Detection and Custom Model Training">
    <title>TensorFlowJS - Emotion Detection & Training</title>

    <!-- Bootstrap 5.3 CSS -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-T3c6CoIi6uLrA9TneNEoa7RxnatzjcDSCmG1MXxSR1GAsXEV/Dwwykc2MPK8M2HN" crossorigin="anonymous">

    <!-- Bootstrap Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.11.2/font/bootstrap-icons.css">

    <!-- TensorFlow.js -->
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@3.11.0/dist/tf.min.js" type="text/javascript"></script>

    <style>
      /* Mobile-First Responsive Styles */
      @media (max-width: 768px) {
        body {
          font-size: 14px;
        }

        #prediction-header {
          font-size: 0.9rem;
        }

        #live-prediction {
          font-size: 1.1rem !important;
        }

        #webcam {
          border-radius: 0.5rem;
        }

        .btn-lg {
          padding: 0.75rem 1rem;
          font-size: 1.1rem;
        }

        .accordion-button {
          padding: 1rem;
          font-size: 1rem;
        }

        .card-body {
          padding: 1rem;
        }

        .progress {
          height: 10px !important;
        }
      }

      /* Smooth transitions for collapsing */
      .accordion-collapse {
        transition: height 0.3s ease;
      }

      /* Prevent video overflow */
      video {
        max-width: 100%;
        height: auto;
        display: block;
      }

      /* Button states for data collection */
      .dataCollector.collecting {
        animation: pulse 1s infinite;
      }

      @keyframes pulse {
        0%, 100% { opacity: 1; }
        50% { opacity: 0.7; }
      }

      /* Loading states */
      .btn:disabled {
        cursor: not-allowed;
        opacity: 0.6;
      }

      /* Video container - Always visible */
      #video-container {
        position: sticky;
        top: 0;
        z-index: 100;
        background-color: white;
        margin-bottom: 1rem;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
      }

      #webcam {
        max-height: 50vh;
        object-fit: cover;
        display: block;
        width: 100%;
      }

      /* Prediction overlay */
      #prediction-overlay {
        position: absolute;
        top: 20px;
        left: 20px;
        background-color: rgba(0, 0, 0, 0.7);
        color: white;
        padding: 15px 20px;
        border-radius: 8px;
        font-size: 1.5rem;
        font-weight: bold;
        z-index: 1000;
        pointer-events: none;
        transition: opacity 0.3s ease;
        backdrop-filter: blur(5px);
      }

      #prediction-overlay.hidden {
        opacity: 0;
      }

      @media (max-width: 768px) {
        #prediction-overlay {
          top: 10px;
          left: 10px;
          padding: 10px 15px;
          font-size: 1.2rem;
        }
      }

      /* Class management styles */
      .class-item {
        border: 1px solid #dee2e6;
        border-radius: 0.375rem;
        padding: 1rem;
        margin-bottom: 1rem;
        background-color: #f8f9fa;
      }

      .class-item-header {
        display: flex;
        justify-content: space-between;
        align-items: center;
        margin-bottom: 0.5rem;
      }

      .class-label-input {
        flex: 1;
        margin-right: 0.5rem;
      }

      /* Sticky emotion detection panel */
      .emotion-panel {
        position: fixed;
        top: 20px;
        right: 20px;
        z-index: 9999;
        min-width: 300px;
        max-width: 350px;
        background: rgba(255, 255, 255, 0.95);
        backdrop-filter: blur(10px);
        padding: 20px;
        border-radius: 15px;
        box-shadow: 0 8px 32px rgba(0,0,0,0.3);
        border: 2px solid rgba(255,255,255,0.3);
      }

      .emotion-panel h3 {
        margin: 0 0 15px 0;
        font-size: 1.3em;
        color: #333;
        border-bottom: 2px solid #198754;
        padding-bottom: 10px;
      }

      .emotion-panel-content {
        font-size: 1.2em;
        font-weight: bold;
        padding: 15px;
        background: linear-gradient(135deg, #198754 0%, #20c997 100%);
        color: white;
        border-radius: 10px;
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
        text-align: center;
        margin-bottom: 10px;
      }

      /* Mobile responsiveness for emotion panel */
      @media (max-width: 768px) {
        .emotion-panel {
          position: fixed;
          top: auto;
          bottom: 0;
          left: 0;
          right: 0;
          min-width: 100%;
          max-width: 100%;
          border-radius: 15px 15px 0 0;
          max-height: 30vh;
          overflow-y: auto;
        }
      }

      /* Portfolio iframe styling */
      .portfolio-iframe-container {
        transition: all 0.3s ease;
        overflow: hidden;
      }

      .portfolio-iframe-container iframe {
        transition: transform 0.3s ease;
      }

      .portfolio-iframe-container:hover iframe {
        transform: scale(1.01);
      }

      /* Better label type button styling */
      .btn-group label.btn {
        min-height: 80px;
        display: flex;
        flex-direction: column;
        justify-content: center;
        align-items: center;
        text-align: center;
      }

      .btn-group label.btn i {
        font-size: 1.5rem;
        margin-bottom: 0.25rem;
      }

      /* Step cards with colored borders */
      .border-primary {
        border-width: 2px !important;
      }

      .border-success {
        border-width: 2px !important;
      }

      .border-warning {
        border-width: 2px !important;
      }

      /* Highlight important buttons */
      #train:hover {
        transform: scale(1.02);
        box-shadow: 0 4px 20px rgba(13, 110, 253, 0.4);
      }
    </style>
  </head>
  <body>
    <!-- Sticky Emotion Detection Panel -->
    <div class="emotion-panel d-none" id="sticky-emotion-panel">
      <h3><i class="bi bi-emoji-smile me-2"></i>Live Emotion</h3>
      <div class="emotion-panel-content" id="sticky-emotion-value">
        Not detecting
      </div>
      <small class="text-muted">Scroll anywhere - emotion stays visible!</small>
    </div>

    <main>
      <!-- Main Container -->
      <div class="container-fluid px-2 py-3">
        <!-- App Title -->
        <h1 class="h4 text-center mb-3">TensorFlow.js - Facial Emotion & Object Detection</h1>

        <!-- Video Container - Always Visible -->
        <div id="video-container" class="card mb-3 shadow-sm">
          <div class="card-body p-2 position-relative">
            <video id="webcam" autoplay muted playsinline class="w-100 rounded"></video>
            <!-- Prediction Overlay -->
            <div id="prediction-overlay" class="hidden">Awaiting...</div>
          </div>
        </div>

        <!-- Bootstrap Accordion for Features -->
        <div class="accordion" id="featuresAccordion">

          <!-- SECTION 1: Camera Setup -->
          <div class="accordion-item">
            <h2 class="accordion-header">
              <button class="accordion-button" type="button" data-bs-toggle="collapse"
                      data-bs-target="#cameraSetup" aria-expanded="true" aria-controls="cameraSetup">
                <i class="bi bi-camera-video me-2"></i> Camera Setup
              </button>
            </h2>
            <div id="cameraSetup" class="accordion-collapse collapse show"
                 data-bs-parent="#featuresAccordion">
              <div class="accordion-body">
                <div class="d-grid gap-2">
                  <button id="enableCam" class="btn btn-lg btn-primary">
                    <i class="bi bi-camera-fill me-2"></i> Enable Camera
                  </button>

                  <div class="btn-group" role="group" aria-label="Camera selection">
                    <button id="useFrontCamera" class="btn btn-outline-secondary">
                      <i class="bi bi-phone me-1"></i> Front
                    </button>
                    <button id="useRearCamera" class="btn btn-outline-secondary">
                      <i class="bi bi-camera me-1"></i> Rear
                    </button>
                  </div>

                  <div id="status" class="alert alert-info small mb-0 mt-2">
                    <div class="d-flex align-items-center">
                      <strong>Awaiting TF.js load</strong>
                      <div class="spinner-border spinner-border-sm ms-auto" id="loadingIndicator"></div>
                    </div>
                  </div>
                </div>
              </div>
            </div>
          </div>

          <!-- SECTION 2: Pre-trained Emotion Detection -->
          <div class="accordion-item">
            <h2 class="accordion-header">
              <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                      data-bs-target="#emotionDetection" aria-expanded="false" aria-controls="emotionDetection">
                <i class="bi bi-emoji-smile me-2"></i> Emotion Detection
              </button>
            </h2>
            <div id="emotionDetection" class="accordion-collapse collapse"
                 data-bs-parent="#featuresAccordion">
              <div class="accordion-body">
                <p class="small text-muted mb-3">
                  Use the pre-trained emotion detection model to identify Happy, Sad, Surprise, or Neutral expressions.
                </p>

                <div class="d-grid gap-2">
                  <button id="detectEmotions" class="btn btn-lg btn-success">
                    <i class="bi bi-emoji-smile-fill me-2"></i> Start Emotion Detection
                  </button>
                  <button id="stopEmotions" class="btn btn-lg btn-danger d-none">
                    <i class="bi bi-stop-circle me-2"></i> Stop Detection
                  </button>
                </div>

                <div id="label-container" class="alert alert-success mt-3 d-none">
                  <strong>Current Emotion:</strong> <span id="emotion-value">--</span>
                </div>
              </div>
            </div>
          </div>

          <!-- SECTION 3: Custom Object Training -->
          <div class="accordion-item">
            <h2 class="accordion-header">
              <button class="accordion-button collapsed" type="button" data-bs-toggle="collapse"
                      data-bs-target="#customTraining" aria-expanded="false" aria-controls="customTraining">
                <i class="bi bi-mortarboard me-2"></i> Train Your Own AI Model (Easy!)
              </button>
            </h2>
            <div id="customTraining" class="accordion-collapse collapse"
                 data-bs-parent="#featuresAccordion">
              <div class="accordion-body">
                <!-- Getting Started Guide -->
                <div class="alert alert-primary mb-3">
                  <h6 class="alert-heading"><i class="bi bi-lightbulb me-2"></i>How This Works (3 Easy Steps!)</h6>
                  <ol class="mb-0 small ps-3">
                    <li><strong>Choose what to recognize:</strong> People or objects</li>
                    <li><strong>Collect examples:</strong> Show the camera what you want it to learn (hold the button!)</li>
                    <li><strong>Train:</strong> Click one button and the AI learns!</li>
                  </ol>
                  <hr class="my-2">
                  <p class="small mb-0"><strong>Example:</strong> Want to tell cats from dogs? Add "Cat" and "Dog" as classes, show your camera examples of each, then train!</p>
                </div>

                <!-- Step 1: Choose What to Recognize -->
                <div class="card mb-3 border-primary">
                  <div class="card-header bg-primary text-white">
                    <h6 class="mb-0"><strong>STEP 1:</strong> What do you want to recognize?</h6>
                  </div>
                  <div class="card-body">
                    <p class="small text-muted mb-2">Choose whether you're training on people or objects/items:</p>
                    <div class="btn-group w-100 mb-2" role="group" aria-label="Label type selection">
                      <input type="radio" class="btn-check" name="labelType" id="labelTypeHuman" value="human" checked>
                      <label class="btn btn-outline-primary" for="labelTypeHuman">
                        <i class="bi bi-person-fill me-1"></i>
                        <div class="d-block">
                          <strong>People</strong>
                          <br><small>Names, faces, etc.</small>
                        </div>
                      </label>

                      <input type="radio" class="btn-check" name="labelType" id="labelTypeItem" value="item">
                      <label class="btn btn-outline-primary" for="labelTypeItem">
                        <i class="bi bi-box-fill me-1"></i>
                        <div class="d-block">
                          <strong>Objects/Items</strong>
                          <br><small>Cats, dogs, toys, etc.</small>
                        </div>
                      </label>
                    </div>
                  </div>
                </div>

                <!-- Funny Mode Toggle (only for humans) -->
                <div class="card mb-3 border-warning" id="funny-mode-card" style="display: none;">
                  <div class="card-header bg-warning">
                    <h6 class="mb-0"><i class="bi bi-emoji-laughing me-2"></i>Fun Mode (Optional)</h6>
                  </div>
                  <div class="card-body">
                    <div class="form-check form-switch mb-2">
                      <input class="form-check-input" type="checkbox" id="funnyModeToggle">
                      <label class="form-check-label" for="funnyModeToggle">
                        <strong>Use silly auto-generated names</strong>
                      </label>
                    </div>
                    <p class="small text-muted mb-0">
                      <i class="bi bi-info-circle me-1"></i>
                      When enabled, names like "Grumpy Pants", "Smiley McSmile" are auto-assigned. Perfect for fun demos!
                    </p>
                  </div>
                </div>

                <!-- Step 2: Data Collection Interface -->
                <div class="card mb-3 border-success">
                  <div class="card-header bg-success text-white">
                    <div class="d-flex justify-content-between align-items-center">
                      <h6 class="mb-0"><strong>STEP 2:</strong> Collect Training Examples</h6>
                      <button id="add-class-btn" class="btn btn-sm btn-light">
                        <i class="bi bi-plus-circle me-1"></i> Add Another
                      </button>
                    </div>
                  </div>
                  <div class="card-body">
                    <div class="alert alert-info mb-3">
                      <h6 class="alert-heading mb-2"><i class="bi bi-question-circle me-2"></i>How to Collect Examples:</h6>
                      <ul class="small mb-0 ps-3">
                        <li><strong>Press and HOLD</strong> the green button while showing the camera what you want it to learn</li>
                        <li>Collect <strong>at least 5 examples</strong> (more is better - up to 25!)</li>
                        <li>Try different angles, lighting, and distances for better results</li>
                        <li>You can also <strong>upload images</strong> instead of using the camera</li>
                      </ul>
                    </div>

                    <!-- Collection Mode Settings -->
                    <div class="card mb-3 bg-light">
                      <div class="card-body">
                        <h6 class="card-title mb-3"><i class="bi bi-gear me-2"></i>Collection Mode</h6>

                        <!-- Mode Toggle -->
                        <div class="btn-group w-100 mb-3" role="group" aria-label="Collection mode">
                          <input type="radio" class="btn-check" name="collectionMode" id="collectionModeAuto" value="auto" checked>
                          <label class="btn btn-outline-secondary" for="collectionModeAuto">
                            <i class="bi bi-fast-forward-fill me-1"></i>
                            <div class="d-block">
                              <strong>Automatic</strong>
                              <br><small>Hold button = many images</small>
                            </div>
                          </label>

                          <input type="radio" class="btn-check" name="collectionMode" id="collectionModeManual" value="manual">
                          <label class="btn btn-outline-secondary" for="collectionModeManual">
                            <i class="bi bi-hand-index me-1"></i>
                            <div class="d-block">
                              <strong>Manual</strong>
                              <br><small>1 click = 1 image</small>
                            </div>
                          </label>
                        </div>

                        <!-- Custom Sample Size (shown in manual mode) -->
                        <div id="customSampleSizeContainer" style="display: none;">
                          <label for="customSampleSize" class="form-label small mb-1">
                            <i class="bi bi-image me-1"></i>How many images per class?
                          </label>
                          <input type="number"
                                 class="form-control"
                                 id="customSampleSize"
                                 min="1"
                                 max="100"
                                 value="25"
                                 placeholder="Enter number of images">
                          <small class="text-muted">In manual mode, click the button this many times to collect all samples</small>
                        </div>

                        <!-- Mode Explanations -->
                        <div class="alert alert-secondary mb-0 mt-2 small" id="autoModeExplanation">
                          <i class="bi bi-info-circle me-1"></i>
                          <strong>Automatic:</strong> Press and hold the button - it collects multiple images per second (up to 25 total)
                        </div>
                        <div class="alert alert-secondary mb-0 mt-2 small" id="manualModeExplanation" style="display: none;">
                          <i class="bi bi-info-circle me-1"></i>
                          <strong>Manual:</strong> Each click collects exactly 1 image. Perfect for precise control over your training data!
                        </div>
                      </div>
                    </div>

                    <div id="classes-container">
                      <!-- Dynamic classes will be added here -->
                    </div>
                  </div>
                </div>

                <!-- Step 3: Training Interface -->
                <div class="card mb-3 border-warning">
                  <div class="card-header bg-warning">
                    <h6 class="mb-0"><strong>STEP 3:</strong> Train Your AI!</h6>
                  </div>
                  <div class="card-body">
                    <div class="alert alert-success mb-3">
                      <i class="bi bi-check-circle me-2"></i>
                      <strong>Ready to train?</strong> Make sure you collected at least 5 examples for each class above. Then click the big button below!
                    </div>
                    <button id="train" class="btn btn-lg btn-primary w-100 mb-3" style="font-size: 1.2rem; padding: 1rem;">
                      <i class="bi bi-rocket-takeoff me-2"></i> <strong>Train AI Now!</strong>
                    </button>

                    <!-- Training Progress (Initially Hidden) -->
                    <div id="training-progress-container" class="d-none">
                      <div class="alert alert-info">
                        <i class="bi bi-hourglass-split me-2"></i>
                        <strong>Training in progress...</strong> The AI is learning from your examples. This usually takes 10-30 seconds.
                      </div>
                      <div class="mb-3">
                        <div class="d-flex justify-content-between align-items-center mb-2">
                          <span class="fw-bold">Progress</span>
                          <span id="epoch-counter" class="badge bg-primary">Epoch 0/10</span>
                        </div>
                        <div class="progress mb-2" style="height: 20px;">
                          <div id="epoch-progress-bar" class="progress-bar progress-bar-striped progress-bar-animated"
                               role="progressbar" style="width: 0%">0%</div>
                        </div>
                      </div>

                      <div class="row g-2 mb-3">
                        <div class="col-6">
                          <div class="card bg-light">
                            <div class="card-body p-2 text-center">
                              <div class="small text-muted">Accuracy</div>
                              <div id="train-accuracy" class="fs-5 fw-bold text-success">--</div>
                              <small class="text-muted">Higher is better</small>
                            </div>
                          </div>
                        </div>
                        <div class="col-6">
                          <div class="card bg-light">
                            <div class="card-body p-2 text-center">
                              <div class="small text-muted">Loss</div>
                              <div id="train-loss" class="fs-5 fw-bold text-danger">--</div>
                              <small class="text-muted">Lower is better</small>
                            </div>
                          </div>
                        </div>
                      </div>

                      <div class="alert alert-secondary small mb-0">
                        <i class="bi bi-clock me-1"></i> Time Remaining: <span id="time-remaining">Calculating...</span>
                      </div>
                    </div>

                    <hr>

                    <button id="reset" class="btn btn-outline-danger w-100">
                      <i class="bi bi-trash me-2"></i> Start Over (Delete All Data)
                    </button>
                    <p class="small text-muted text-center mt-2 mb-0">
                      <i class="bi bi-exclamation-triangle me-1"></i>
                      Warning: This will erase all collected examples
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </div>

        </div><!-- end accordion -->

        <!-- Info Card -->
        <div class="card mt-3">
          <div class="card-body">
            <h5 class="card-title">About This Application</h5>
            <p class="card-text small">
              This application uses TensorFlow.js to run deep neural networks directly in your browser.
              The emotion detection model classifies facial expressions, while the custom training feature
              uses transfer learning with MobileNet v3 to train on your own objects.
            </p>
            <p class="card-text small text-muted">
              Emotion Model Built and Trained by Robert Sloan - MIT Applied Data Science Program
            </p>
          </div>
        </div>

        <!-- Applied Data Science Portfolio Section -->
        <div class="card mt-4">
          <div class="card-header bg-success text-white">
            <h5 class="mb-0"><i class="bi bi-mortarboard me-2"></i>MIT Applied Data Science Program Portfolio</h5>
          </div>
          <div class="card-body">
            <p class="card-text">
              This emotion detection project was completed as part of the capstone for MIT's Applied Data Science Program.
              View the complete portfolio showcasing all projects and learnings from the program.
            </p>
            <a href="https://robertsloan22.github.io/AppliedDataScience/" target="_blank" class="btn btn-success mb-3">
              <i class="bi bi-box-arrow-up-right me-2"></i>View Full Applied Data Science Portfolio
            </a>

            <!-- Embedded Portfolio Preview -->
            <div class="mt-3">
              <h6><i class="bi bi-display me-2"></i>Portfolio Preview:</h6>
              <p class="text-muted small">Interactive preview of the Applied Data Science portfolio page</p>
              <div class="portfolio-iframe-container">
                <div class="ratio ratio-16x9" style="max-height: 600px;">
                  <iframe
                    src="https://robertsloan22.github.io/AppliedDataScience/"
                    title="Applied Data Science Portfolio"
                    style="border: 2px solid #198754; border-radius: 10px; background: #f8f9fa;"
                    allowfullscreen
                    loading="lazy">
                  </iframe>
                </div>
              </div>
              <p class="text-muted small mt-2">
                <em>Click the button above to open the full portfolio in a new tab, or scroll within the preview to explore.</em>
              </p>
            </div>
          </div>
        </div>

      </div><!-- end container -->
    </main>

    <!-- Bootstrap Bundle JS -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-C6RzsynM9kWDrMNeT87bh95OGNyZPhcTNXj1NW7RuBCsyN/o0jlpcV8Qyq46cDfL" crossorigin="anonymous"></script>

    <!-- Main Application Script -->
    <script>
      // ========== CONSTANTS ==========
      const STATUS = document.getElementById('status');
      const VIDEO = document.getElementById('webcam');
      const ENABLE_CAM_BUTTON = document.getElementById('enableCam');
      const RESET_BUTTON = document.getElementById('reset');
      const TRAIN_BUTTON = document.getElementById('train');
      const MOBILE_NET_INPUT_WIDTH = 224;
      const MOBILE_NET_INPUT_HEIGHT = 224;
      const STOP_DATA_GATHER = -1;
      let MAX_SAMPLES_PER_CLASS = 25; // Can be changed by user in manual mode
      let COLLECTION_MODE = 'auto'; // 'auto' or 'manual'
      const CLASS_NAMES = [];
      const CLASS_COLORS = ['#0d6efd', '#ffc107', '#198754', '#0dcaf0', '#dc3545', '#6f42c1', '#fd7e14', '#20c997'];
      const FUNNY_LABELS = ['jerk face', 'emo sad pants', 'This Guy smells', 'Total Stud Muffin', 'Grumpy Pants', 'Smiley McSmile', 'Sleepy Head', 'Angry Bird'];
      let labelType = 'human'; // 'human' or 'item'
      let funnyMode = false;
      let nextClassId = 0;

      // ========== GLOBAL STATE ==========
      let mobilenet = undefined;
      let gatherDataState = STOP_DATA_GATHER;
      let videoPlaying = false;
      let trainingDataInputs = [];
      let trainingDataOutputs = [];
      let examplesCount = [];
      let predict = false;
      let trainingStartTime = null;
      let currentStream = null;
      let emodel = null;
      let isDetecting = false;
      let model = null;

      // ========== INITIALIZATION ==========
      document.addEventListener('DOMContentLoaded', function() {
        const loadingIndicator = document.getElementById('loadingIndicator');
        loadingIndicator.style.visibility = 'visible';

        if (typeof tf !== 'undefined') {
          console.log('TensorFlow.js loaded successfully');
          STATUS.innerHTML = '<strong>TF.js Loaded Successfully</strong>';
          loadingIndicator.style.visibility = 'hidden';
        } else {
          console.error('Failed to load TensorFlow.js');
          STATUS.innerHTML = '<strong class="text-danger">Failed to load TF.js</strong>';
        }
      });

      // ========== CAMERA FUNCTIONS ==========
      function hasGetUserMedia() {
        return !!(navigator.mediaDevices && navigator.mediaDevices.getUserMedia);
      }

      async function enableCam() {
        if (hasGetUserMedia()) {
          if (currentStream) {
            currentStream.getTracks().forEach(track => track.stop());
          }

          const constraints = {
            video: {
              facingMode: 'user',
              width: { ideal: 640 },
              height: { ideal: 480 }
            }
          };

          try {
            const stream = await navigator.mediaDevices.getUserMedia(constraints);
            VIDEO.srcObject = stream;
            currentStream = stream;

            VIDEO.addEventListener('loadeddata', function() {
              videoPlaying = true;
              STATUS.innerHTML = '<strong class="text-success">Camera enabled successfully!</strong>';
            });
          } catch (error) {
            console.error('Camera access denied:', error);
            STATUS.innerHTML = '<strong class="text-danger">Camera access denied</strong>';
          }
        } else {
          console.warn('getUserMedia() is not supported by your browser');
          STATUS.innerHTML = '<strong class="text-warning">Camera not supported</strong>';
        }
      }

      async function switchCamera(facingMode = 'user') {
        if (navigator.mediaDevices.getUserMedia) {
          if (currentStream) {
            currentStream.getTracks().forEach(track => track.stop());
          }

          try {
            const stream = await navigator.mediaDevices.getUserMedia({
              video: {
                facingMode: facingMode,
                width: { ideal: 640 },
                height: { ideal: 480 }
              }
            });
            VIDEO.srcObject = stream;
            currentStream = stream;
            STATUS.innerHTML = `<strong class="text-success">Switched to ${facingMode === 'user' ? 'front' : 'rear'} camera</strong>`;
          } catch (error) {
            console.error('Camera switch error:', error);
            STATUS.innerHTML = '<strong class="text-danger">Failed to switch camera</strong>';
          }
        }
      }

      // ========== MOBILENET LOADING ==========
      async function loadMobileNetFeatureModel() {
        try {
          const URL = 'https://tfhub.dev/google/tfjs-model/imagenet/mobilenet_v3_small_100_224/feature_vector/5/default/1';

          mobilenet = await tf.loadGraphModel(URL, {fromTFHub: true});
          STATUS.innerHTML += '<br><strong class="text-success">MobileNet v3 loaded successfully!</strong>';

          // Warm up the model
          tf.tidy(function () {
            let answer = mobilenet.predict(tf.zeros([1, MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH, 3]));
            console.log('MobileNet output shape:', answer.shape);
          });
        } catch (error) {
          console.error('Error loading MobileNet:', error);
          STATUS.innerHTML += '<br><strong class="text-danger">Failed to load MobileNet</strong>';
        }
      }

      loadMobileNetFeatureModel();

      // ========== MODEL SETUP ==========
      function rebuildModel() {
        if (model) {
          model.dispose();
        }
        
        const numClasses = Math.max(CLASS_NAMES.length, 2);
        model = tf.sequential();
        model.add(tf.layers.dense({inputShape: [1024], units: 128, activation: 'relu'}));
        model.add(tf.layers.dense({units: 128, activation: 'relu'}));
        model.add(tf.layers.dense({units: numClasses, activation: 'softmax'}));

        model.compile({
          optimizer: 'adam',
          loss: numClasses === 2 ? 'binaryCrossentropy' : 'categoricalCrossentropy',
          metrics: ['accuracy']
        });
      }

      rebuildModel();

      // ========== FUNNY MODE ==========
      function getFunnyLabel(index) {
        return FUNNY_LABELS[index % FUNNY_LABELS.length];
      }

      function generateLabel(classIndex) {
        if (labelType === 'human' && funnyMode) {
          return getFunnyLabel(classIndex);
        }
        return CLASS_NAMES[classIndex] || `${labelType === 'human' ? 'Human' : 'Item'} ${classIndex + 1}`;
      }

      // ========== CLASS MANAGEMENT ==========
      function addClass() {
        if (predict) {
          alert('Please stop prediction before adding classes.');
          return;
        }
        
        const classIndex = CLASS_NAMES.length;
        const defaultName = labelType === 'human' 
          ? (funnyMode ? getFunnyLabel(classIndex) : `Human ${classIndex + 1}`)
          : `Item ${classIndex + 1}`;
        
        CLASS_NAMES.push(defaultName);
        examplesCount.push(0);
        renderClasses();
        rebuildModel();
      }

      function removeClass(classIndex) {
        if (CLASS_NAMES.length <= 1) {
          alert('You need at least one class!');
          return;
        }

        if (predict) {
          alert('Please stop prediction before removing classes.');
          return;
        }

        if (trainingDataInputs.length > 0) {
          if (!confirm('Removing a class will reset all collected data. Continue?')) {
            return;
          }
          reset();
        }

        CLASS_NAMES.splice(classIndex, 1);
        examplesCount.splice(classIndex, 1);
        
        // Update training data indices if needed
        for (let i = trainingDataOutputs.length - 1; i >= 0; i--) {
          if (trainingDataOutputs[i] === classIndex) {
            trainingDataInputs[i].dispose();
            trainingDataInputs.splice(i, 1);
            trainingDataOutputs.splice(i, 1);
          } else if (trainingDataOutputs[i] > classIndex) {
            trainingDataOutputs[i]--;
          }
        }

        renderClasses();
        rebuildModel();
      }

      function updateClassName(classIndex, newName) {
        if (newName.trim()) {
          CLASS_NAMES[classIndex] = newName.trim();
        }
      }

      function renderClasses() {
        const container = document.getElementById('classes-container');
        container.innerHTML = '';

        CLASS_NAMES.forEach((className, index) => {
          const classItem = document.createElement('div');
          classItem.className = 'class-item';
          classItem.id = `class-item-${index}`;

          const color = CLASS_COLORS[index % CLASS_COLORS.length];
          const isHuman = labelType === 'human';
          const showLabelInput = isHuman && !funnyMode;

          classItem.innerHTML = `
            <div class="class-item-header">
              <div class="d-flex align-items-center flex-grow-1">
                ${showLabelInput ? `
                  <input type="text" 
                         class="form-control form-control-sm class-label-input" 
                         id="class-label-${index}" 
                         value="${className}" 
                         placeholder="Enter name..."
                         data-class-index="${index}">
                ` : `
                  <label class="form-label mb-0 fw-bold" id="class-label-${index}">${className}</label>
                `}
                <span id="class-${index}-counter" class="badge bg-secondary ms-2">0/${MAX_SAMPLES_PER_CLASS}</span>
              </div>
              ${CLASS_NAMES.length > 1 ? `
                <button class="btn btn-sm btn-outline-danger remove-class-btn" data-class-index="${index}">
                  <i class="bi bi-trash"></i>
                </button>
              ` : ''}
            </div>
            <div class="progress mb-2" style="height: 8px;">
              <div id="class-${index}-progress-bar" 
                   class="progress-bar" 
                   role="progressbar"
                   style="width: 0%; background-color: ${color};"
                   aria-valuenow="0" 
                   aria-valuemin="0" 
                   aria-valuemax="${MAX_SAMPLES_PER_CLASS}"></div>
            </div>
            <button class="dataCollector btn btn-lg w-100 mb-2"
                    data-1hot="${index}" 
                    data-name="${className}" 
                    id="collectClass${index}"
                    style="background-color: ${color}; border-color: ${color};">
              <i class="bi bi-record-circle me-2"></i> 
              <span id="collectClass${index}-text">Collect ${className} Samples</span>
            </button>
            <div class="input-group">
              <input type="file" 
                     class="form-control form-control-sm image-upload-input" 
                     id="uploadClass${index}"
                     accept="image/*"
                     multiple
                     data-class-index="${index}"
                     style="display: none;">
              <label for="uploadClass${index}" 
                     class="btn btn-sm btn-outline-secondary w-100" 
                     style="cursor: pointer;">
                <i class="bi bi-upload me-1"></i> Upload Images
              </label>
            </div>
          `;

          container.appendChild(classItem);

          // Add event listeners
          const collectBtn = classItem.querySelector('.dataCollector');
          collectBtn.addEventListener('mousedown', startDataCollection);
          collectBtn.addEventListener('touchstart', startDataCollection);
          collectBtn.addEventListener('mouseup', stopDataCollection);
          collectBtn.addEventListener('touchend', stopDataCollection);
          collectBtn.addEventListener('mouseleave', stopDataCollection);

          if (showLabelInput) {
            const labelInput = classItem.querySelector('.class-label-input');
            labelInput.addEventListener('blur', (e) => {
              updateClassName(index, e.target.value);
              updateClassButtonText(index);
            });
            labelInput.addEventListener('keypress', (e) => {
              if (e.key === 'Enter') {
                e.target.blur();
              }
            });
          }

          const removeBtn = classItem.querySelector('.remove-class-btn');
          if (removeBtn) {
            removeBtn.addEventListener('click', () => removeClass(index));
          }

          // Add file upload event listener
          const uploadInput = classItem.querySelector('.image-upload-input');
          if (uploadInput) {
            uploadInput.addEventListener('change', (e) => handleImageUpload(e, index));
          }

          // Update UI with current count
          updateDataCollectionUI(index, examplesCount[index] || 0);
        });
      }

      function updateClassButtonText(classIndex) {
        const button = document.getElementById(`collectClass${classIndex}`);
        const textSpan = document.getElementById(`collectClass${classIndex}-text`);
        if (button && textSpan) {
          const label = CLASS_NAMES[classIndex];
          textSpan.textContent = `Collect ${label} Samples`;
          button.setAttribute('data-name', label);
        }
      }

      // ========== LABEL TYPE MANAGEMENT ==========
      function updateLabelType() {
        const selectedType = document.querySelector('input[name="labelType"]:checked').value;
        labelType = selectedType;

        // Stop prediction if running
        if (predict) {
          predict = false;
        }

        // Show/hide funny mode card
        const funnyModeCard = document.getElementById('funny-mode-card');
        funnyModeCard.style.display = labelType === 'human' ? 'block' : 'none';

        // Reset if data has been collected (to prevent confusion)
        if (trainingDataInputs.length > 0) {
          if (confirm('Changing label type will reset all collected data. Continue?')) {
            reset();
          } else {
            // Revert the radio button
            document.getElementById(labelType === 'human' ? 'labelTypeItem' : 'labelTypeHuman').checked = true;
            updateLabelType();
            return;
          }
        }

        // Initialize with 2 classes if empty
        if (CLASS_NAMES.length === 0) {
          for (let i = 0; i < 2; i++) {
            const defaultName = labelType === 'human' 
              ? (funnyMode ? getFunnyLabel(i) : `Human ${i + 1}`)
              : `Item ${i + 1}`;
            CLASS_NAMES.push(defaultName);
            examplesCount.push(0);
          }
        } else {
          // Update existing class names
          CLASS_NAMES.forEach((name, index) => {
            if (labelType === 'human') {
              CLASS_NAMES[index] = funnyMode ? getFunnyLabel(index) : `Human ${index + 1}`;
            } else {
              CLASS_NAMES[index] = `Item ${index + 1}`;
            }
          });
        }

        renderClasses();
        rebuildModel();
      }

      function updateFunnyMode() {
        funnyMode = document.getElementById('funnyModeToggle').checked;
        
        if (labelType === 'human') {
          // Stop prediction if running
          if (predict) {
            predict = false;
          }
          
          // Update all class names
          CLASS_NAMES.forEach((name, index) => {
            CLASS_NAMES[index] = funnyMode ? getFunnyLabel(index) : `Human ${index + 1}`;
          });
          
          if (trainingDataInputs.length > 0) {
            if (!confirm('Changing funny mode will reset all collected data. Continue?')) {
              document.getElementById('funnyModeToggle').checked = !funnyMode;
              funnyMode = !funnyMode;
              return;
            }
            reset();
          }
          
          renderClasses();
        }
      }

      // ========== IMAGE UPLOAD ==========
      async function handleImageUpload(event, classIndex) {
        const files = event.target.files;
        if (!files || files.length === 0) return;

        if (!mobilenet) {
          alert('MobileNet model is still loading. Please wait...');
          return;
        }

        // Check if we have room for more samples
        const currentCount = examplesCount[classIndex] || 0;
        const remainingSlots = MAX_SAMPLES_PER_CLASS - currentCount;
        
        if (remainingSlots <= 0) {
          alert(`Maximum samples (${MAX_SAMPLES_PER_CLASS}) already collected for this class.`);
          event.target.value = ''; // Reset file input
          return;
        }

        const filesToProcess = Array.from(files).slice(0, remainingSlots);
        let processedCount = 0;

        for (const file of filesToProcess) {
          if (examplesCount[classIndex] >= MAX_SAMPLES_PER_CLASS) {
            break;
          }

          try {
            // Create image element
            const img = new Image();
            const imageUrl = URL.createObjectURL(file);
            
            await new Promise((resolve, reject) => {
              img.onload = resolve;
              img.onerror = reject;
              img.src = imageUrl;
            });

            // Process image through MobileNet (same as webcam frames)
            const imageFeatures = tf.tidy(function() {
              let imageTensor = tf.browser.fromPixels(img);
              let resizedTensorFrame = tf.image.resizeBilinear(
                imageTensor,
                [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH],
                true
              );
              let normalizedTensorFrame = resizedTensorFrame.div(255);
              return mobilenet.predict(normalizedTensorFrame.expandDims()).squeeze();
            });

            // Add to training data
            trainingDataInputs.push(imageFeatures);
            trainingDataOutputs.push(classIndex);

            // Update count
            if (examplesCount[classIndex] === undefined) {
              examplesCount[classIndex] = 0;
            }
            examplesCount[classIndex]++;
            processedCount++;

            // Update UI
            updateDataCollectionUI(classIndex, examplesCount[classIndex]);

            // Clean up
            URL.revokeObjectURL(imageUrl);
          } catch (error) {
            console.error('Error processing image:', error);
            alert(`Error processing image: ${file.name}`);
          }
        }

        // Reset file input
        event.target.value = '';

        if (processedCount > 0) {
          console.log(`Processed ${processedCount} image(s) for class ${classIndex}`);
        }
      }

      // ========== DATA COLLECTION ==========
      // Initialize with 2 classes
      updateLabelType();

      // Add event listeners for label type changes
      document.querySelectorAll('input[name="labelType"]').forEach(radio => {
        radio.addEventListener('change', updateLabelType);
      });

      // Add class button
      document.getElementById('add-class-btn').addEventListener('click', addClass);

      // Funny mode toggle
      document.getElementById('funnyModeToggle').addEventListener('change', updateFunnyMode);

      // Collection mode event listeners
      document.querySelectorAll('input[name="collectionMode"]').forEach(radio => {
        radio.addEventListener('change', updateCollectionMode);
      });

      document.getElementById('customSampleSize').addEventListener('change', updateSampleSize);

      function updateCollectionMode(event) {
        COLLECTION_MODE = event.target.value;
        const customSizeContainer = document.getElementById('customSampleSizeContainer');
        const autoExplanation = document.getElementById('autoModeExplanation');
        const manualExplanation = document.getElementById('manualModeExplanation');

        if (COLLECTION_MODE === 'manual') {
          customSizeContainer.style.display = 'block';
          autoExplanation.style.display = 'none';
          manualExplanation.style.display = 'block';
          // Update MAX_SAMPLES_PER_CLASS from input
          updateSampleSize();
        } else {
          customSizeContainer.style.display = 'none';
          autoExplanation.style.display = 'block';
          manualExplanation.style.display = 'none';
          MAX_SAMPLES_PER_CLASS = 25; // Reset to default
          renderClasses(); // Re-render to update counters
        }
      }

      function updateSampleSize() {
        const input = document.getElementById('customSampleSize');
        const value = parseInt(input.value);
        if (value && value > 0 && value <= 100) {
          MAX_SAMPLES_PER_CLASS = value;
          renderClasses(); // Re-render to update all counters
        }
      }

      function startDataCollection(event) {
        event.preventDefault();
        const button = event.target.closest('.dataCollector');
        const classNumber = parseInt(button.getAttribute('data-1hot'));

        // Don't start if already at max
        if (examplesCount[classNumber] >= MAX_SAMPLES_PER_CLASS) {
          return;
        }

        // Don't start if already collecting (auto mode only)
        if (COLLECTION_MODE === 'auto' && gatherDataState !== STOP_DATA_GATHER) {
          return;
        }

        // Manual mode: collect single image
        if (COLLECTION_MODE === 'manual') {
          collectSingleImage(classNumber);
          return;
        }

        // Auto mode: continuous collection
        gatherDataState = classNumber;
        button.classList.add('collecting');
        dataGatherLoop();
      }

      function collectSingleImage(classNumber) {
        if (!videoPlaying) {
          console.log('Video not ready');
          return;
        }

        // Check if we've reached the limit
        if (examplesCount[classNumber] >= MAX_SAMPLES_PER_CLASS) {
          console.log(`Reached maximum samples (${MAX_SAMPLES_PER_CLASS}) for class ${classNumber}`);
          return;
        }

        // Collect one image
        let imageFeatures = tf.tidy(function() {
          let videoFrameAsTensor = tf.browser.fromPixels(VIDEO);
          let resizedTensorFrame = tf.image.resizeBilinear(
            videoFrameAsTensor,
            [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH],
            true
          );
          let normalizedTensorFrame = resizedTensorFrame.div(255);
          return mobilenet.predict(normalizedTensorFrame.expandDims()).squeeze();
        });

        trainingDataInputs.push(imageFeatures);
        trainingDataOutputs.push(classNumber);

        // Initialize array index element if currently undefined
        if (examplesCount[classNumber] === undefined) {
          examplesCount[classNumber] = 0;
        }
        examplesCount[classNumber]++;

        // Update UI with counter and progress bar
        updateDataCollectionUI(classNumber, examplesCount[classNumber]);

        // Add visual feedback
        const button = document.getElementById(`collectClass${classNumber}`);
        if (button) {
          button.classList.add('collecting');
          setTimeout(() => {
            button.classList.remove('collecting');
          }, 200);
        }

        console.log(`Collected image ${examplesCount[classNumber]}/${MAX_SAMPLES_PER_CLASS} for class ${classNumber}`);
      }

      function stopDataCollection(event) {
        event.preventDefault();

        if (gatherDataState !== STOP_DATA_GATHER) {
          gatherDataState = STOP_DATA_GATHER;
          document.querySelectorAll('.dataCollector').forEach(btn => {
            btn.classList.remove('collecting');
          });
        }
      }

      function dataGatherLoop() {
        if (videoPlaying && gatherDataState !== STOP_DATA_GATHER) {
          // Check if we've reached the limit for this class
          if (examplesCount[gatherDataState] >= MAX_SAMPLES_PER_CLASS) {
            console.log(`Reached maximum samples (${MAX_SAMPLES_PER_CLASS}) for class ${gatherDataState}`);
            gatherDataState = STOP_DATA_GATHER;
            updateDataCollectionUI(gatherDataState < 0 ? 0 : gatherDataState, examplesCount[gatherDataState] || 0);
            return;
          }

          let imageFeatures = tf.tidy(function() {
            let videoFrameAsTensor = tf.browser.fromPixels(VIDEO);
            let resizedTensorFrame = tf.image.resizeBilinear(
              videoFrameAsTensor,
              [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH],
              true
            );
            let normalizedTensorFrame = resizedTensorFrame.div(255);
            return mobilenet.predict(normalizedTensorFrame.expandDims()).squeeze();
          });

          trainingDataInputs.push(imageFeatures);
          trainingDataOutputs.push(gatherDataState);

          // Initialize array index element if currently undefined
          if (examplesCount[gatherDataState] === undefined) {
            examplesCount[gatherDataState] = 0;
          }
          examplesCount[gatherDataState]++;

          // Update UI with counter and progress bar
          updateDataCollectionUI(gatherDataState, examplesCount[gatherDataState]);

          window.requestAnimationFrame(dataGatherLoop);
        }
      }

      function updateDataCollectionUI(classId, count) {
        const counterId = `class-${classId}-counter`;
        const progressBarId = `class-${classId}-progress-bar`;
        const counterElement = document.getElementById(counterId);
        const progressBar = document.getElementById(progressBarId);

        if (counterElement) {
          counterElement.textContent = `${count}/${MAX_SAMPLES_PER_CLASS}`;

          // Change badge color based on progress
          counterElement.classList.remove('bg-secondary', 'bg-warning', 'bg-success');
          if (count === 0) {
            counterElement.classList.add('bg-secondary');
          } else if (count < MAX_SAMPLES_PER_CLASS) {
            counterElement.classList.add('bg-warning');
          } else {
            counterElement.classList.add('bg-success');
          }
        }

        if (progressBar) {
          const percentage = (count / MAX_SAMPLES_PER_CLASS) * 100;
          progressBar.style.width = `${percentage}%`;
          progressBar.setAttribute('aria-valuenow', count);
        }

        // Update button state
        const button = document.getElementById(`collectClass${classId}`);
        if (button && count >= MAX_SAMPLES_PER_CLASS) {
          button.disabled = true;
          const buttonTextSpan = document.getElementById(`collectClass${classId}-text`);
          if (buttonTextSpan) {
            button.innerHTML = `<i class="bi bi-check-circle me-2"></i> <span id="collectClass${classId}-text">25 Samples Collected!</span>`;
          }
          button.classList.remove('collecting');
        } else if (button) {
          button.disabled = false;
        }
      }

      // ========== TRAINING ==========
      async function trainAndPredict() {
        // Validate sufficient training data
        const totalSamples = trainingDataInputs.length;
        const minSamplesPerClass = 5;
        
        // Check if we have at least minSamplesPerClass for each class
        const classCounts = {};
        trainingDataOutputs.forEach(output => {
          classCounts[output] = (classCounts[output] || 0) + 1;
        });
        
        const classesWithEnoughSamples = Object.keys(classCounts).filter(
          classId => classCounts[classId] >= minSamplesPerClass
        );
        
        if (classesWithEnoughSamples.length < CLASS_NAMES.length) {
          alert(`Please collect at least ${minSamplesPerClass} samples for each class before training.`);
          return;
        }
        
        if (totalSamples < CLASS_NAMES.length * minSamplesPerClass) {
          alert(`Please collect at least ${minSamplesPerClass} samples per class before training.`);
          return;
        }

        // Disable train button during training
        TRAIN_BUTTON.disabled = true;
        TRAIN_BUTTON.innerHTML = `
          <span class="spinner-border spinner-border-sm me-2" aria-hidden="true"></span>
          Training...
        `;

        predict = false;

        // Shuffle data for better training
        tf.util.shuffleCombo(trainingDataInputs, trainingDataOutputs);

        // Prepare tensors
        let outputsAsTensor = tf.tensor1d(trainingDataOutputs, 'int32');
        let oneHotOutputs = tf.oneHot(outputsAsTensor, CLASS_NAMES.length);
        let inputsAsTensor = tf.stack(trainingDataInputs);

        try {
          // Train model with progress callback
          let results = await model.fit(inputsAsTensor, oneHotOutputs, {
            shuffle: true,
            batchSize: 5,
            epochs: 10,
            callbacks: {onEpochEnd: logProgress}
          });

          console.log('Training complete:', results);

          // Enable prediction mode
          predict = true;
          predictLoop();

        } catch (error) {
          console.error('Training error:', error);
          alert('Training failed. Please try again.');
        } finally {
          // Cleanup tensors
          outputsAsTensor.dispose();
          oneHotOutputs.dispose();
          inputsAsTensor.dispose();

          // Re-enable button
          TRAIN_BUTTON.disabled = false;
          TRAIN_BUTTON.innerHTML = '<i class="bi bi-play-circle me-2"></i> Start Training';
        }
      }

      function logProgress(epoch, logs) {
        console.log('Data for epoch ' + epoch, logs);

        // Show training progress container on first epoch
        if (epoch === 0) {
          trainingStartTime = Date.now();
          document.getElementById('training-progress-container').classList.remove('d-none');
        }

        const totalEpochs = 10;

        // Update epoch counter
        const epochCounter = document.getElementById('epoch-counter');
        epochCounter.textContent = `Epoch ${epoch + 1}/${totalEpochs}`;

        // Update progress bar
        const progressBar = document.getElementById('epoch-progress-bar');
        const progressPercentage = ((epoch + 1) / totalEpochs) * 100;
        progressBar.style.width = `${progressPercentage}%`;
        progressBar.textContent = `${Math.round(progressPercentage)}%`;

        // Update accuracy metric
        const accuracy = logs.acc || logs.accuracy;
        if (accuracy !== undefined) {
          document.getElementById('train-accuracy').textContent = `${(accuracy * 100).toFixed(1)}%`;
        }

        // Update loss metric
        if (logs.loss !== undefined) {
          document.getElementById('train-loss').textContent = logs.loss.toFixed(4);
        }

        // Calculate and update estimated time remaining
        if (epoch > 0 && trainingStartTime) {
          const currentTime = Date.now();
          const avgTimePerEpoch = (currentTime - trainingStartTime) / (epoch + 1);
          const remainingEpochs = totalEpochs - (epoch + 1);
          const estimatedMs = avgTimePerEpoch * remainingEpochs;

          const seconds = Math.floor(estimatedMs / 1000);
          const minutes = Math.floor(seconds / 60);
          const remainingSeconds = seconds % 60;

          let timeString = '';
          if (minutes > 0) {
            timeString = `${minutes}m ${remainingSeconds}s`;
          } else {
            timeString = `${remainingSeconds}s`;
          }

          document.getElementById('time-remaining').textContent = timeString;
        }

        // Training complete
        if (epoch === totalEpochs - 1) {
          document.getElementById('time-remaining').textContent = 'Complete!';
          epochCounter.classList.remove('bg-primary');
          epochCounter.classList.add('bg-success');
          trainingStartTime = null;
        }
      }

      // ========== PREDICTION ==========
      function predictLoop() {
        if (predict) {
          tf.tidy(function() {
            let videoFrameAsTensor = tf.browser.fromPixels(VIDEO).div(255);
            let resizedTensorFrame = tf.image.resizeBilinear(
              videoFrameAsTensor,
              [MOBILE_NET_INPUT_HEIGHT, MOBILE_NET_INPUT_WIDTH],
              true
            );

            let imageFeatures = mobilenet.predict(resizedTensorFrame.expandDims());
            let prediction = model.predict(imageFeatures).squeeze();
            let highestIndex = prediction.argMax().arraySync();
            let predictionArray = prediction.arraySync();

            // Update overlay prediction
            const overlay = document.getElementById('prediction-overlay');
            const confidence = Math.floor(predictionArray[highestIndex] * 100);
            const displayLabel = generateLabel(highestIndex);
            overlay.textContent = `${displayLabel} (${confidence}%)`;
            overlay.classList.remove('hidden');
            
            // Update overlay background color
            const color = CLASS_COLORS[highestIndex % CLASS_COLORS.length];
            // Convert hex to rgba
            const r = parseInt(color.slice(1, 3), 16);
            const g = parseInt(color.slice(3, 5), 16);
            const b = parseInt(color.slice(5, 7), 16);
            overlay.style.backgroundColor = `rgba(${r}, ${g}, ${b}, 0.7)`;
          });

          window.requestAnimationFrame(predictLoop);
        }
      }

      // ========== RESET FUNCTION ==========
      function reset() {
        predict = false;
        isDetecting = false;

        // Clear training data
        examplesCount.length = 0;
        for (let i = 0; i < trainingDataInputs.length; i++) {
          trainingDataInputs[i].dispose();
        }
        trainingDataInputs.length = 0;
        trainingDataOutputs.length = 0;

        // Reset UI elements
        STATUS.innerHTML = '<strong>No data collected</strong>';
        
        // Hide overlay
        const overlay = document.getElementById('prediction-overlay');
        overlay.classList.add('hidden');
        overlay.textContent = 'Awaiting...';

        // Reset counters and progress bars
        for (let i = 0; i < CLASS_NAMES.length; i++) {
          examplesCount[i] = 0;
          updateDataCollectionUI(i, 0);

          // Re-enable buttons
          const button = document.getElementById(`collectClass${i}`);
          if (button) {
            button.disabled = false;
            const buttonTextSpan = document.getElementById(`collectClass${i}-text`);
            if (buttonTextSpan) {
              button.innerHTML = `<i class="bi bi-record-circle me-2"></i> <span id="collectClass${i}-text">Collect ${CLASS_NAMES[i]} Samples</span>`;
            }
            button.classList.remove('collecting');
          }
        }

        // Hide training progress
        document.getElementById('training-progress-container').classList.add('d-none');

        // Reset training metrics
        document.getElementById('train-accuracy').textContent = '--';
        document.getElementById('train-loss').textContent = '--';
        document.getElementById('epoch-counter').textContent = 'Epoch 0/10';
        document.getElementById('epoch-counter').classList.remove('bg-success');
        document.getElementById('epoch-counter').classList.add('bg-primary');
        document.getElementById('epoch-progress-bar').style.width = '0%';
        document.getElementById('epoch-progress-bar').textContent = '0%';

        console.log('Tensors in memory: ' + tf.memory().numTensors);
      }

      // ========== EMOTION DETECTION ==========
      async function loadEModel() {
        try {
          const labelContainer = document.getElementById('label-container');
          const livePrediction = document.getElementById('live-prediction');

          labelContainer.textContent = 'Loading Emotion Detection model...';
          labelContainer.classList.remove('d-none');

          emodel = await tf.loadLayersModel('public/facialemotions/model.json');

          labelContainer.textContent = 'Emotion Model loaded successfully!';
          labelContainer.classList.add('alert-success');

          // Enable detect button
          document.getElementById('detectEmotions').disabled = false;
        } catch (error) {
          console.error('Error loading emotion model:', error);
          const labelContainer = document.getElementById('label-container');
          labelContainer.textContent = 'Failed to load emotion model';
          labelContainer.classList.add('alert-danger');
          labelContainer.classList.remove('d-none');
        }
      }

      loadEModel();

      async function predictEmotion() {
        if (!emodel || !isDetecting || VIDEO.readyState !== 4) {
          if (isDetecting) {
            setTimeout(predictEmotion, 500);
          }
          return;
        }

        try {
          const predictions = tf.tidy(() => {
            const img = tf.browser.fromPixels(VIDEO)
              .resizeNearestNeighbor([48, 48])
              .toFloat()
              .div(tf.scalar(255.0))
              .expandDims(0);
            return emodel.predict(img);
          });

          const prediction = await predictions.data();
          const maxIndex = prediction.indexOf(Math.max(...prediction));
          const emotions = ['Happy', 'Sad', 'Surprise', 'Neutral'];
          const confidence = Math.floor(prediction[maxIndex] * 100);

          // Update overlay for emotion detection
          const overlay = document.getElementById('prediction-overlay');
          overlay.textContent = `${emotions[maxIndex]} (${confidence}%)`;
          overlay.classList.remove('hidden');
          overlay.style.backgroundColor = 'rgba(25, 135, 84, 0.7)'; // Green for emotions

          // Update label container
          const labelContainer = document.getElementById('label-container');
          labelContainer.classList.remove('d-none');
          labelContainer.classList.add('alert-success');
          document.getElementById('emotion-value').textContent = `${emotions[maxIndex]} - ${confidence}% confidence`;

          // Update sticky emotion panel
          const stickyPanel = document.getElementById('sticky-emotion-panel');
          const stickyValue = document.getElementById('sticky-emotion-value');
          stickyPanel.classList.remove('d-none');
          stickyValue.textContent = `${emotions[maxIndex]} (${confidence}%)`;

          tf.dispose(predictions);
        } catch (error) {
          console.error('Prediction error:', error);
        }

        // Continue predicting
        if (isDetecting) {
          setTimeout(predictEmotion, 500);
        }
      }

      // ========== EVENT LISTENERS ==========
      ENABLE_CAM_BUTTON.addEventListener('click', enableCam);
      TRAIN_BUTTON.addEventListener('click', trainAndPredict);
      RESET_BUTTON.addEventListener('click', reset);

      document.getElementById('useFrontCamera').addEventListener('click', () => {
        switchCamera('user');
      });

      document.getElementById('useRearCamera').addEventListener('click', () => {
        switchCamera('environment');
      });

      document.getElementById('detectEmotions').addEventListener('click', () => {
        if (!isDetecting) {
          isDetecting = true;
          predictEmotion();
          document.getElementById('detectEmotions').classList.add('d-none');
          document.getElementById('stopEmotions').classList.remove('d-none');
        }
      });

      document.getElementById('stopEmotions').addEventListener('click', () => {
        isDetecting = false;
        document.getElementById('detectEmotions').classList.remove('d-none');
        document.getElementById('stopEmotions').classList.add('d-none');
        const overlay = document.getElementById('prediction-overlay');
        overlay.classList.add('hidden');
        const labelContainer = document.getElementById('label-container');
        labelContainer.textContent = 'Emotion detection stopped';
        labelContainer.classList.remove('alert-success');
        labelContainer.classList.add('alert-warning');

        // Hide sticky emotion panel
        const stickyPanel = document.getElementById('sticky-emotion-panel');
        const stickyValue = document.getElementById('sticky-emotion-value');
        stickyPanel.classList.add('d-none');
        stickyValue.textContent = 'Not detecting';
      });
    </script>
  </body>
</html>
